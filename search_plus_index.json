{"./":{"url":"./","title":"介绍","keywords":"","body":"fujianchao's blog! 🍀 "},"SUMMARY.html":{"url":"SUMMARY.html","title":"目录","keywords":"","body":"Summary 介绍 目录 Redis Redis - 简介 Redis - 配置参数说明 设计模式 六大原则 单例模式 "},"06-Redis/":{"url":"06-Redis/","title":"Redis","keywords":"","body":"Redis REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API 它通常被称为数据结构服务器 , 因为值(value)可以是 字符串(String), 哈希(Map) , 列表(list) , 集合(sets) 和有序集合(sorted sets)等类型 "},"06-Redis/01-Redis - 简介.html":{"url":"06-Redis/01-Redis - 简介.html","title":"Redis - 简介","keywords":"","body":"Redis - 简介 介绍 🍀 REmote DIctionary Server(Redis) 是一个由 Salvatore Sanfilippo 写的 key-value 存储系统 Redis是一个开源的使用 ANSI C 语言编写 , 遵守BSD协议 , 支持网络 , 可基于内存亦可持久化的日志型 , Key-Value 数据库 , 并提供多种语言的API 特点 Redis 与其他 key - value 缓存产品有以下三个特点 : Redis支持数据的持久化 , 可以将内存中的数据保持在磁盘中 , 重启的时候可以再次加载进行使用 Redis不仅仅支持简单的 key-value 类型的数据 , 同时还提供 list , set , zset , hash等数据结构的存储 Redis支持数据的备份 , 即 master-slave 模式的数据备份 优势 性能极高 – Redis能读的速度是 110000次/s , 写的速度是 81000次/s 丰富的数据类型 – Redis支持二进制案例的 Strings , Lists , Hashes , Sets 及 Ordered Sets 数据类型操作 原子 – Redis的所有操作都是原子性的 , 同时Redis还支持对几个操作全并后的原子性执行 丰富的特性 – Redis还支持 publish/subscribe , 通知 key 过期等等特性 安装 🍀 方式一 $ yum isntall redis 运行 $ redis-server /etc/redis.conf 方式二 : $ wget http://download.redis.io/releases/redis-4.0.10.tar.gz $ tar xzf redis-4.0.10.tar.gz $ cd redis-4.0.10 $ make 运行 $ src/redis-server 与内置客户端进行交互 : $ src/redis-cli redis> set foo bar OK redis> get foo \"bar\" 配置 🍀 Redis 的配置文件位于 Redis 安装目录下 , 文件名为 redis.conf 我们可以通过 CONFIG 命令查看或者设置配置项 查看配置 🍀 语法 redis 127.0.0.1:6379> CONFIG GET CONFIG_SETTING_NAME 实例 redis 127.0.0.1:6379> CONFIG GET loglevel 1) \"loglevel\" 2) \"notice\" 使用 * 号获取所有配置项 : redis 127.0.0.1:6379> CONFIG GET * 修改配置 🍀 你可以通过修改 redis.conf 文件或使用 CONFIG SET 命令来修改配置 语法 redis 127.0.0.1:6379> CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE 实例 redis 127.0.0.1:6379> CONFIG SET loglevel \"notice\" OK redis 127.0.0.1:6379> CONFIG GET loglevel 1) \"loglevel\" 2) \"notice\" 数据类型 🍀 Redis支持五种数据类型 : string (字符串) , hash (哈希) , list (列表) , set (集合) 及 zset(sorted set : 有序集合) String 🍀 string 是 Redis 最基本的类型 , 你可以理解成与 Memcached 一模一样的类型 , 一个 key 对应一个 value string 类型是二进制安全的 , 意思是 Redis 的 string 可以包含任何数据 , 比如 jpg 图片或者序列化的对象 string 类型是 Redis 最基本的数据类型 , 一个键最大能存储 512 MB 实例 redis 127.0.0.1:6379> SET name \"redis.net.cn\" OK redis 127.0.0.1:6379> GET name \"redis.net.cn\" 在以上实例中我们使用了 Redis 的 SET 和 GET 命令 , 键为 name , 对应的值为redis.net.cn 注意 : 一个键最大能存储 512 MB Hash 🍀 Redis hash 是一个键值对集合 Redis hash 是一个 string 类型的 field 和 value 的映射表 , hash 特别适合用于存储对象 实例 redis 127.0.0.1:6379> HMSET user:1 username redis.net.cn password redis.net.cn points 200 OK redis 127.0.0.1:6379> HGETALL user:1 1) \"username\" 2) \"redis.net.cn\" 3) \"password\" 4) \"redis.net.cn\" 5) \"points\" 6) \"200\" redis 127.0.0.1:6379> 以上实例中 hash 数据类型存储了包含用户脚本信息的用户对象 , 实例中我们使用了 Redis HMSET , HEGTALL 命令 , user:1 为键值 每个 hash 可以存储 2^(32-1) 键值对 , 相当于 40 多亿 List 🍀 Redis 列表是简单的字符串列表 , 按照插入顺序排序 , 你可以添加一个元素导列表的头部 (左边) 或者尾部 (右边) 实例 redis 127.0.0.1:6379> lpush redis.net.cn redis (integer) 1 redis 127.0.0.1:6379> lpush redis.net.cn mongodb (integer) 2 redis 127.0.0.1:6379> lpush redis.net.cn rabitmq (integer) 3 redis 127.0.0.1:6379> lrange redis.net.cn 0 10 1) \"rabitmq\" 2) \"mongodb\" 3) \"redis\" redis 127.0.0.1:6379> 列表最多可存储 2^(32-1) 元素 (4294967295 , 每个列表可存储40多亿) Set 🍀 Redis 的 Set 是 string 类型的无序集合 集合是通过哈希表实现的 , 所以添加 , 删除 , 查找的复杂度都是 O(1) sadd 命令 添加一个 string 元素到 , key 对应的 set 集合中 , 成功返回 1 ,如果元素以及在集合中返回 0 , key 对应的 set 不存在返回错误 sadd key member 实例 redis 127.0.0.1:6379> sadd redis.net.cn redis (integer) 1 redis 127.0.0.1:6379> sadd redis.net.cn mongodb (integer) 1 redis 127.0.0.1:6379> sadd redis.net.cn rabitmq (integer) 1 redis 127.0.0.1:6379> sadd redis.net.cn rabitmq (integer) 0 redis 127.0.0.1:6379> smembers redis.net.cn 1) \"rabitmq\" 2) \"mongodb\" 3) \"redis\" 注意 : 以上实例中 rabitmq 添加了两次 , 但根据集合内元素的唯一性 , 第二次插入的元素将被忽略 集合中最大的成员数为 2^(32-1) (4294967295, 每个集合可存储40多亿个成员) zset 🍀 Redis zset 和 Set 一样也是string类型元素的集合 , 且不允许重复的成员 不同的是每个元素都会关联一个 double 类型的分数 , redis 正是通过分数来为集合中的成员进行从小到大的排序。 zset 的成员是唯一的 , 但分数 (score) 却可以重复 zadd 命令 添加元素到集合 , 元素在集合中存在则更新对应 score zadd key score member 实例 redis 127.0.0.1:6379> zadd redis.net.cn 0 redis (integer) 1 redis 127.0.0.1:6379> zadd redis.net.cn 0 mongodb (integer) 1 redis 127.0.0.1:6379> zadd redis.net.cn 0 rabitmq (integer) 1 redis 127.0.0.1:6379> zadd redis.net.cn 0 rabitmq (integer) 0 redis 127.0.0.1:6379> ZRANGEBYSCORE redis.net.cn 0 1000 1) \"redis\" 2) \"mongodb\" 3) \"rabitmq\" "},"06-Redis/02-Redis - 配置参数说明.html":{"url":"06-Redis/02-Redis - 配置参数说明.html","title":"Redis - 配置参数说明","keywords":"","body":"Redis - 配置参数说明 参数说明 🍀 redis.conf 配置项说明如下 : Redis 默认不是以守护进程的方式运行 , 可以通过该配置项修改 , 使用yes启用守护进程 daemonize no 当 Redis 以守护进程方式运行时 , Redis 默认会把 pid 写入 /var/run/redis.pid 文件 , 可以通过 pidfile 指定 pidfile /var/run/redis.pid 指定 Redis 监听端口 , 默认端口为 6379 , 作者在自己的一篇博文中解释了为什么选用 6379 作为默认端口 , 因为 6379 在手机按键上 MERZ 对应的号码 , 而 MERZ 取自意大利歌女 Alessia Merz 的名字 port 6379 绑定的主机地址 bind 127.0.0.1 当客户端闲置多长时间后关闭连接 , 如果指定为0 , 表示关闭该功能 timeout 300 指定日志记录级别 , Redis总共支持四个级别 : debug , verbose , notice , warning , 默认为 verbose loglevel verbose 日志记录方式 , 默认为标准输出 , 如果配置 Redis 为守护进程方式运行 , 而这里又配置为日志记录方式为标准输出 , 则日志将会发送给 /dev/null logfile stdout 设置数据库的数量 , 默认数据库为0 , 可以使用SELECT 命令在连接上指定数据库id databases 16 指定在多长时间内 , 有多少次更新操作 , 就将数据同步到数据文件 , 可以多个条件配合 save Redis 默认配置文件中提供了三个条件 : save 900 1 save 300 10 save 60 10000 分别表示900秒 ( 15分钟 ) 内有1个更改 , 300秒 ( 5分钟)内有10个更改以及60秒内有10000个更改 指定存储至本地数据库时是否压缩数据 , 默认为yes , Redis 采用 LZF 压缩 , 如果为了节省 CPU 时间 , 可以关闭该选项 , 但会导致数据库文件变的巨大 rdbcompression yes 指定本地数据库文件名 , 默认值为 dump.rdb dbfilename dump.rdb 指定本地数据库存放目录 dir ./ 设置当本机为 slav 服务时 , 设置 master 服务的IP地址及端口 , 在 Redis 启动时 , 它会自动从 master 进行数据同步 slaveof 当 master 服务设置了密码保护时 , slav 服务连接 master 的密码 masterauth 设置 Redis 连接密码 , 如果配置了连接密码 , 客户端在连接Redis时需要通过 AUTH 命令提供密码 , 默认关闭 requirepass foobared 设置同一时间最大客户端连接数 , 默认无限制 , Redis 可以同时打开的客户端连接数为 Redis 进程可以打开的最大文件描述符数 , 如果设置 maxclients 0 , 表示不作限制 , 当客户端连接数到达限制时 , Redis 会关闭新的连接并向客户端返回 max number of clients reached 错误信息 maxclients 128 指定 Redis 最大内存限制 , Redis 在启动时会把数据加载到内存中 , 达到最大内存后 , Redis 会先尝试清除已到期或即将到期的 Key , 当此方法处理 后 , 仍然到达最大内存设置 , 将无法再进行写入操作 , 但仍然可以进行读取操作 , Redis 新的 vm 机制 , 会把 Key 存放内存 , Value 会存放在 swap 区 maxmemory 指定是否在每次更新操作后进行日志记录 , Redis 在默认情况下是异步的把数据写入磁盘 , 如果不开启 , 可能会在断电时导致一段时间内的数据丢失 , 因为 redis本身同步数据文件是按上面 save 条件来同步的 , 所以有的数据会在一段时间内只存在于内存中 , 默认为no appendonly no 指定更新日志文件名 , 默认为 appendonly.aof appendfilename appendonly.aof 指定更新日志条件 , 共有3个可选值 : no : 表示等操作系统进行数据缓存同步到磁盘 ( 快 ) always : 表示每次更新操作后手动调用 fsync() 将数据写到磁盘 ( 慢 , 安全 ) everysec : 表示每秒同步一次 ( 折衷 , 默认值 ) appendfsync everysec 指定是否启用虚拟内存机制 , 默认值为no , 简单的介绍一下 , VM 机制将数据分页存放 , 由 Redis 将访问量较少的页即冷数据 swap 到磁盘上 , 访问多的页面由磁盘自动换出到内存中 ( 在后面的文章我会仔细分析Redis的VM机制 ) vm-enabled no 虚拟内存文件路径 , 默认值为 /tmp/redis.swap , 不可多个Redis实例共享 vm-swap-file /tmp/redis.swap 将所有大于 vm-max-memory 的数据存入虚拟内存,无论 vm-max-memory 设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys) , 也就是说,当 vm-max-memory 设置为 0 的时候,其实是所有value 都存在于磁盘 , 默认值为 0 vm-max-memory 0 Redis swap文件分成了很多的 page , 一个对象可以保存在多个 page 上面 , 但一个 page 上不能被多个对象共享 , vm-page-size 是要根据存储的 数据大小来设定的 , 作者建议如果存储很多小对象 , page 大小最好设置为 32 或者 `4bytes ; 如果存储很大大对象 , 则可以使用更大的 page , 如果不 确定 , 就使用默认值 vm-page-size 32 设置 swap 文件中的 page 数量 , 由于页表 ( 一种表示页面空闲或使用的bitmap ) 是在放在内存中的 , 在磁盘上每 8 个 pages 将消耗 1byte 的内存 , vm-pages 134217728 设置访问 swap 文件的线程数,最好不要超过机器的核数,如果设置为 0 , 那么所有对 swap 文件的操作都是串行的 , 可能会造成比较长时间的延迟 , 默认值为 4 vm-max-threads 4 设置在向客户端应答时 , 是否把较小的包合并为一个包发送 , 默认为开启 glueoutputbuf yes 指定在超过一定的数量或者最大的元素超过某一临界值时 , 采用一种特殊的哈希算法 hash-max-zipmap-entries 64 hash-max-zipmap-value 512 指定是否激活重置哈希 , 默认为开启 ( 后面在介绍Redis的哈希算法时具体介绍 ) activerehashing yes 指定包含其它的配置文件 , 可以在同一主机上多个 Redis 实例之间使用同一份配置文件 , 而同时各个实例又拥有自己的特定配置文件 include /path/to/local.conf "},"07-设计模式/":{"url":"07-设计模式/","title":"设计模式","keywords":"","body":"设计模式 "},"07-设计模式/01-六大原则.html":{"url":"07-设计模式/01-六大原则.html","title":"六大原则","keywords":"","body":"六大原则 前言 🍀 设计模式是一个我们编写程序的标准 , 也就是一种规范 , 有时候不能够盲目的追求规范而不理会真实情景 , 因为它可能会适得其反 单一职责原则 🍀 单一职责原则 (Single Responsibility Principle , 简称 SRP ) 定义 : 应该有且仅有一个原因引起类的变更 (原话 : There should never be more than one reason for a class to change. ) 作用 : 降低类的复杂性 , 职责具有清晰明确的定义 提高可读性 提供可维护性 降低变更引起的风险 实例 : 以通话为例 , 我们需要两个操作来实现通话 建立连接 信息传递 伪代码示例 class Phone(object): \"\"\" 未区分职责, converse既负责连接, 也负责信息传递 \"\"\" def converse(self, phone, message): 连接 开始通话 挂断电话 class Phone(object): \"\"\" 区分职责, dial负责连接, chat负责信息传递, hangup负责关闭连接 \"\"\" def dial(self, phone): pass def chat(self, message): pass def hangup(): pass 变更的出现会使你的项目工作量增大 , 所以单一职责原则可以有效的提高你的工作效率 , 但是通常你可能感觉不到它的存在 , 第一是因为你可能会不自觉的这么去做 , 即使它不完全符合这一原则 ; 第二是因为你的项目不允许去深究它 , 总之 , 单一职责原则可以在一定程度上使你的代码更加从容面对项目遇到的变更风险 扩展 : 在面向对象中, 除了继承, 还有另一种方式来实现抽象, 那就是组合, 但是组合是一种强耦合关系, 所以不到迫不得已还是不要使用组合的好 里氏替换原则 🍀 里氏替换原则 (Liskov substitution Principle , 简称 LSP ) 定义 : 如果对每一个类型为 S 的对象 o1 , 都有类型为 T 的对象 o2 , 使得以 T 定义的所有程序 P 在所有的对象 o1 都代换成 o2 时, 程序 P 的行为没有发生变化, 那么类型 S 是类型 T 的子类型 (原话 : If for each object o1 of type S there is an object o2 of type T such that for all programs P defined in terms of T, the behavior of P is unchanged when o1 is substituted for o2 then S is a subtype of T.) 大致意思就是 , 父类能出现的地方子类也可以出现 , 而且替换将父类替换成子类也不会产生任何错误或异常 , 使用者可能根本就不需要知道是父类还是子类 , 但是 , 反过来子类能出现的地方父类却不一定能出现 , 它的含义如下 : 子类必须完全实现父类的方法 (但是如果子类中的某些方法发生了畸变 , 建议将方法进行独立) 子类可以有自己的个性 覆盖或实现父类的方法时输入参数可以被放大 覆盖或实现父类的方法时输出结果可以被缩小 关于第一点和第二点 , 这几乎就是基本的规则 , 不过在 Python 中并没有接口的概念 , 当然而第三点和第四点则是需要注意的 , 因为一旦参数被缩小 , 或者结果被放大 , 那你在写代码时就得小心了 , 因为你要顾及你的子类是否能正常完成你的任务 作用 : 代码共享 , 减少创建类的工作量 , 每个子类都拥有父类的方法和属性 提高代码的重用性 子类可以形似父类 , 但又异于父类 提高代码的可扩展性 提高产品或项目的开放性 实例 : class Foo(object): def say_hello(self, name): print(name, 'hello~') return self class SubOne(Foo): # 重载, 放大参数 def say_hello(self, name, desc=''): print(name, 'hello', '') return self # 异于父类 def say_hi(self, name): print(name, 'hi') class SubTwo(Foo): # 覆盖 def say_hello(self, name): print('hello', name) return self 这个例子可以说是用来 \"凑数\" 的 , 因为在 Python 中 , 来表达里氏替换原则所有的含义可能会不太像 Python 了 , 因为Python 天生就是多态 , 所以也不需要接口 ; 但是覆盖和重载我们应该遵循里氏替换原则 , 为了保证更好的兼容性 , 扩展性 扩展 : 覆盖(Override) 和重载 (Overload) : 覆盖就意味着它的外观是没有任何变化的 , 使用起来也没有变化 , 但是它其中的内容却已经被改变 ; 重载则是它的名字还是一样的 , 但是也仅仅是名字 , 它的其他都已经被重新塑造 ; 就比如 , 我们写了一个方法( Python 注解形式) a(n: int, m: str) -> str , 子类覆盖你所看到的还是 a(n: int, m: str) -> str , 而重载 a(n: tuple) -> str , 它只是名字还叫 a , 但是它的参数等等已经发生了改变 依赖倒置原则 🍀 依赖倒置原则 (Dependence Inversion Principle , 简称 DIP ) 定义 : 高层模块不应该依赖底层模块 , 两者应该依赖其抽象 ; 抽象不应该依赖于细节 , 细节应该依赖抽象 ( 原话 : High level modules should not depend upon low level modules.Both should depend upon abstractions.Abstractions should not depend upon details.Details should depend upon abstractions. ) 依赖倒置原则是 \"面向接口编程\" OOD (Object-Oriented Design , 面向对象设计) 的精髓之一 作用 : 减少类之间的耦合性 提高系统的稳定性 降低并行开发引起的风险 提高代码的可读性和可维护性 实例 : # 不符合依赖倒置原则 class Benz(object): def run(self): print('奔驰启动...滴滴滴') class BMW(object): def run(self): print('宝马启动...滴滴滴') class Driver(object): \"\"\"驾驶者\"\"\" def drive(self, benz_ojbect): \"\"\"开奔驰\"\"\" benz_object.run() def drive_BMW(self, bmw_object): \"\"\"为了保证兼容性, \"\"\" bmw_object.run() # 符合依赖倒置原则 class Car(object): \"\"\"抽象类\"\"\" def run(self): \"\"\"细节实现应该依赖于抽象\"\"\" raise NotImplementedError('车必须实现run方法') class Benz(Car): def run(self): print('奔驰启动...滴滴滴') class BMW(Car): def run(self): print('宝马启动...滴滴滴') class Driver(object): \"\"\"根据实际需要, 司机也可以抽象出来\"\"\" def drive(self, car): car.run() \"\"\" 抽象不依赖于细节, 即 Car 不应该依赖于 Benz 和 BMW \"\"\" 依赖有三种写法 , 分别为 : 构造函数传递依赖对象 , 在创建对象时进行限制 方法传递依赖对象 , 在使用过程中进行限制 接口传递依赖对象 , 直接在定义上限制 上述例子所使用的是接口传递依赖对象 依赖倒置原则的本职就是通过抽象 , 使各个类或模块的实现彼此独立 , 不互相影响 , 实现模块间的松耦合 接口隔离原则 🍀 接口隔离原则 (Interface Segregation Principle , 简称 ISP ) 定义 : 客户端不应该依赖它不需要的接口 ; 类之间的依赖关系应该建立在最小的接口上 (原话 : “Clients should not be forced to depend upon interfaces that they don't use. The dependency of one class to another one should depend on the smallest possible interface. ) 注意 , 接口隔离原则和单一职责原则审视的角度是不一样的 , 单一职责是要求类或接口职责单一 , 注重的是职责 , 而接口隔离则要求接口的方法尽量少 , 如 : 一个接口的职责可能包含了 10 个方法 , 这10个方法都放在一个接口中 , 并提供给多个模块访问 , 各个模块按照规定的权限来访问 作用 : 提高代码的灵活性和可维护性 提高系统的内聚性 , 降低系统的耦合性 提高代码重用性 , 减少代码冗余 接口隔离原则是对接口进行规范约束 , 其包含以下四层含义 : 接口要尽量小 接口要高内聚 (高内聚: 提高接口、类、模块的处理能力 , 减少对外的交互 ; 高内聚的标准是既符合接口隔离原则又符合单一职责原则) 定制服务 (只提供访问者需要的方法) 接口设计是有限度的 在进行接口隔离时 , 首先必须要满足单一职责原则 实例 : # 未进行接口隔离 class Worker(object): \"\"\"工人\"\"\" def work(self): \"\"\"需要按顺序完成四道工序\"\"\" step1 step2 step3 step4 # 进行了接口隔离 class Worker(object): \"\"\"工人\"\"\" def work(self): self.finish_step1() self.finish_step2() self.finish_step3() self.finish_step4() def finish_step1(self): pass def finish_step2(self): pass def finish_step3(self): pass def finish_step4(self): pass \"\"\" 场景一: 由于材料更加精细, 已经不需要进行第1道工序了, 只需完成2,3,4道即算完成 场景二: 为了能够让员工更加专注, 每个工人将只负责一道工序 工人A负责第一道工序 工人B负责第二道工序 工人C负责第三道工序 工人D负责第四道工序 场景三: 公司研发出了新的产品P1和P2, 工作流程如下: - P1: 工序数量不变, 但是工作顺序需要倒序, 即 4, 3, 2, 1 - P2: 只需要经过第3道工序, 1,2,4皆不需要 隔离与未隔离哪一种更加能适应以上所有场景? \"\"\" 如果大量的重复代码出现在你的程序中 , 那么你就应该反思了 , 因为你没有进行接口隔离 , 或者隔离得还不够细 , 导致代码无法重用 在进行接口隔离时 , 粒度大小不能过大 , 也不能过小 ; 定义太大 , 会降低灵活性 , 无法提供定制服务 , 给整体项目带来无法预料的风险 ; 定义太小 , 则会造成接口数量过多 , 使设计复杂化 迪米特法则 🍀 迪米特法则 (Law of Demeter , 简称 LoD ) 也称最少知识原则 (Least Knowledge Principle , 简称 LKP) 定义 : 一个对象应该对其他对象有最少的了解 , 即 一个类应该对自己需要耦合或调用的类知道得最少 (原话 : Only talk to your immediate friends ) 他强调以下两点 : 从依赖者的角度来说 , 只依赖应该依赖的对象 从被依赖者的角度来说 , 只暴露应该暴露的方法 迪米特法则的核心观念就是类间解耦 , 弱耦合 , 只有弱耦合了以后 , 类的复用率才可以提高 ; 但是其要求的结果就是产生了大量的中转或跳转类 , 导致系统的复杂性提高 , 同时也为维护带来了难度 , 所以在采用迪米特法则时需要反复权衡 , 既做到让结果清晰 , 又做到高内聚低耦合 作用 : 降低类之间的耦合度 , 提高模块的相对独立性 提高类的可复用率和系统的扩展性 实例 : # 对于明星来说, 经纪人是明星的朋友, 而粉丝是陌生人 class Agent(object): \"\"\"经纪人\"\"\" def set_star(self, star_obj): self.star = star_obj def set_fans(self, fans_obj): self.fans = fans_obj def meeting(self): out_string = ''.join(['粉丝', self.fans.get_name(), '与明星', self.star.get_name(), '见面了.']) print(out_string) class Star(object): \"\"\"明星\"\"\" def __init__(self, name): self.name = name def get_name(self): return self.name class Fans(object): \"\"\"粉丝\"\"\" def __init__(self, name): self.name = name def get_name(self): return self.name 总之 , 迪米特法则的作用在就是解耦 , 但是解耦的程度需要我们格外小心 开闭原则 🍀 开闭原则 定义 : 软件实体应该对扩展开放 , 对修改关闭 . 其含义是说一个软件实体应该通过扩展来实现变化 , 而不是通过修改已有的代码来实现变化 (原话 : Software entities like classes,modules and functions should be open for extension but closed for modifications. ) 开闭原则是面向对象程序设计的终极目标 所有已经投产的代码都是有意义的 , 并且都受系统规则的约束 , 这样的代码都要经过 “千锤百炼” 的测试过程，不仅保证逻辑是正确的，还要保证苛刻条件（高压力、异常、错误）下不产生 “有毒代码” , 因此有变化提出时 , 我们就需要考虑一下 , 原有的健壮代码是否可以不修改 , 仅仅通过扩展实现变化呢 ? 否则 , 就需要把原有的测试过程回笼一遍 , 需要进行单元测试 , 功能测试 , 集成测试甚至是验收测试 作用 : 提高代码的可复用性 提高软件的可维护性 前面5个原则是对开闭原则的具体解释 , 但是开闭原则并不局限于这么多 , 它没有边界 , 我们要把它应用到实际工作中需要注意以下几点 : 抽象约束 , 抽象层尽量保持稳定 元数据控制模块行为 (元数据 : 用来描述环境和数据的数据 , 通常说的就是配置参数) 指定项目章程 , 约定优于配置 封装变化 , 将相同的变化封装到一个接口或抽象类中 , 将不同的变化封装到不同的接口或抽象中 "},"07-设计模式/02-单例模式.html":{"url":"07-设计模式/02-单例模式.html","title":"单例模式","keywords":"","body":"单例模式 🍀 定义 🍀 单例模式 ( Singleton Pattern ) 确保某一个类只有一个实例 , 而且自行实例化并向整个系统提供这个实例 ( Ensure a class has only one instance, and provide a global point of access to it. ) 场景 🍀 在一个系统中 , 要求一个类有且仅有一个对象 , 如果出现多个对象就会出现 \"不良反应\" , 可以采用单例模式 如 : 在整个项目中需要一个共享访问点或共享数据 要生成唯一数据 创建一个对象需要消耗的资源过多 , 如要访问 IO 和数据库等资源 需要定义大量的静态常量和静态方法 (如工具类) 的环境 我们可能最多见的就是需要共享数据 , 比如在项目中的配置数据 , 又比如 Web 框架中的路由 实例 🍀 要实现单例模式 , 即保证一个类仅有一个实例 , 并提供一个访问它的全局访问点 Module 🍀 Python 中的 module 天生就是单例 , 至于为什么 , 你应该去看看 compiled-python-file singleton.py class Singleton(object): pass singleton = Singleton() 使用 from singleton import singleton __new__ 🍀 Python 中的对象将有 __new__ 来开辟空间创建实例 import threading class Singleton(object): _threading_lock = threading.RLock() def __new__(cls, *args, **kwargs): if not hasattr(cls, \"_instance\"): with cls._threading_lock: if not hasattr(cls, \"_instance\"): cls._instance = object.__new__(cls) return cls._instance Python 是支持多线程的 , 所以为了线程安全 , 加上锁 Metaclass 🍀 使用元类来实现单例模式 , 实际上就是控制 class() 的行为 , 也就是 __call__ 魔术方法 如果对于 metaclass 不懂 , 你可以看我的另一篇博客 《Python之路 - 元类》 class SingletonMeta(type): _instances = {} def __call__(self, *args, **kwargs): if self not in self._instances: self._instances[self] = super(SingletonMeta, self).__call__(*args, **kwargs) return self._instances[self] class Singleton(metaclass=SingletonMeta): pass singleton = Singleton() 元类创建类本身就是线程安全的 , 所以你并不需要担心抢占资源的问题 类装饰器 🍀 def singleton(cls): _instance = {} def _singleton(*args, **kargs): if cls not in _instance: _instance[cls] = cls(*args, **kargs) return _instance[cls] return _singleton @singleton class Singleton: pass 使用类装饰器 , 实际上就是把类转换成一个函数对象 , 因此跟实例的创建关系不大 , 因为从始至终也就实例化了一次 , 而且它是线程安全的 类方法 🍀 通过我们自定义的方法来获取对象 , 而不通过实例化的途径 class Singleton(object): @classmethod def instance(cls, *args, **kwargs): if not hasattr(cls, \"_instance\"): cls._instance = cls(*args, **kwargs) return cls._instance singleton = Singleton.instance() 虽然这种方式也能实现单例模式 , 但是它不是线程安全的 , 就算在方法里加了锁 , 也不是线程安全的 , 这里可能跟 Python 的类的加载机制有关 , 不深究了 注意 : 在测试过程中 , 千万要把 Python 的垃圾回收这一问题隔离 , 也就是说实例不要一实例化之后就丢弃 , 否则可能会出现无效的结果 "}}